{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Data import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where I develop the functions to import the data - from .wav files, into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchaudio\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv(\"DATA_DIR\")\n",
    "temp_file = '1.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimbo/Documents/coding/misc/audio-deepfake-detection/venv/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = torchaudio.transforms.MelSpectrogram(16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor, target_length):\n",
    "    '''\n",
    "    Given a tensor and a target length, pads the tensor so that its length a multiple of the target length -\n",
    "    so that it can be split into equal parts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : torch.tensor\n",
    "        The tensor to pad\n",
    "    target_length : int\n",
    "        The target length to pad the tensor to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.tensor\n",
    "        The padded tensor\n",
    "    '''\n",
    "    \n",
    "    _, length = tensor.shape\n",
    "    if length % target_length != 0:\n",
    "        # Calculate padding needed\n",
    "        padding_needed = target_length - (length % target_length)\n",
    "        # Pad the tensor\n",
    "        tensor = torch.nn.functional.pad(tensor, (0, padding_needed))\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file, target_length=80):\n",
    "    '''\n",
    "    Given a file path, loads the file, creates a mel spectrogram, pads it to be cleanly divisible by target_length,\n",
    "    and splits it into chunks of target_length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        The file path to load\n",
    "    target_length : int\n",
    "        The target length to split the tensor into\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of torch.tensor\n",
    "        A tuple of tensors, each of length target_length\n",
    "    '''\n",
    "\n",
    "    # load wav file\n",
    "    waveform, _ = torchaudio.load(file, normalize=True)\n",
    "    waveform = waveform.squeeze(0)\n",
    "\n",
    "    # create mel spectrogram\n",
    "    mel_specgram = transform(waveform)\n",
    "\n",
    "    # pad tensor so it's cleanly divisible by target_length\n",
    "    padded_tensor = pad_tensor(mel_specgram, target_length)\n",
    "\n",
    "    # return the tensor, split into target_length chunks\n",
    "    return padded_tensor.split(target_length, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wav file\n",
    "waveform, sample_rate = torchaudio.load(os.path.join(data_dir, temp_file), normalize=True)\n",
    "waveform = waveform.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_specgram = transform(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 888])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_specgram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tens = pad_tensor(mel_specgram, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_tens.split(80, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_loaded = load_file(os.path.join(data_dir, temp_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(meta_file, \n",
    "                 target_length=80, \n",
    "                 batch_size=32,\n",
    "                 files_to_load='all'):\n",
    "    '''\n",
    "    Given a meta file, loads in the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meta_file : str\n",
    "        The meta file to load\n",
    "    target_length : int\n",
    "        The target length to split the tensor into\n",
    "    batch_size : int\n",
    "        The batch size to use for the DataLoader\n",
    "    files_to_load : int or 'all'\n",
    "        The number of files to load. If 'all', all files are loaded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of torch.tensor\n",
    "        A tuple of tensors - the positives and negatives\n",
    "    '''\n",
    "\n",
    "    positives = []\n",
    "    negatives = []\n",
    "\n",
    "    # Load the meta file\n",
    "    meta = pd.read_csv(meta_file)\n",
    "\n",
    "    # iterate through the files\n",
    "    for i, row in enumerate(meta.itertuples()):\n",
    "        \n",
    "        # If we're only loading a subset of the files, check if we've loaded enough\n",
    "        if files_to_load != 'all' and i >= files_to_load:\n",
    "            break\n",
    "\n",
    "        # Load the file\n",
    "        file_tensors = load_file(os.path.join(data_dir, row.file), target_length=target_length)\n",
    "\n",
    "        # Add the tensors to the appropriate list\n",
    "        for tensor in file_tensors:\n",
    "            if row.numeric_label == 1:\n",
    "                positives.append(tensor)\n",
    "            else:\n",
    "                negatives.append(tensor)\n",
    "\n",
    "    # Create labels\n",
    "    positive_labels = torch.ones(len(positives))\n",
    "    negative_labels = torch.zeros(len(negatives))\n",
    "\n",
    "    # Combine the inputs\n",
    "    data = torch.cat((torch.stack(positives), torch.stack(negatives)), dim=0)\n",
    "    # Combine the labels\n",
    "    labels = torch.cat((positive_labels, negative_labels), dim=0)\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = TensorDataset(data, labels)\n",
    "\n",
    "    # Create a dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # return the dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = load_dataset('train_meta.csv', files_to_load=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Batch data shape: torch.Size([32, 128, 80])\n",
      "Batch labels: tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Batch data shape: torch.Size([23, 128, 80])\n",
      "Batch labels: tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "for batch_data, batch_labels in dataloader:\n",
    "    print(f\"Batch data shape: {batch_data.shape}\")\n",
    "    print(f\"Batch labels: {batch_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
